# 卷积神经网络

## 6.1. 从全连接层到卷积

多层感知机(MLP)十分适合处理表格数据，其中行对应样本，列对应特征。但是对于高维感知数据并不是很实用。

例如，在之前猫狗分类的例子中：假设我们有一个足够充分的照片数据集，数据集中是拥有标注的照片，每张照片具有百万级像素，这意味着网络的每次输入都有一百万个维度。 即使将隐藏层维度降低到1000，这个全连接层也将有10^6^×10^3^=10^9^个参数。 想要训练这个模型将不可实现，因为需要有大量的GPU、分布式优化训练的经验和超乎常人的耐心。

*卷积神经网络*（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。

### 6.1.1. 不变性

假设你想从一张图片中找到某个物体。 合理的假设是：无论哪种方法找到这个物体，都应该和物体的位置无关。

现在，我们将上述想法总结一下，从而帮助我们设计适合于计算机视觉的神经网络架构：

1. *平移不变性*（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
2. *局部性*（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，在后续神经网络，整个图像级别上可以集成这些局部特征用于预测。

即是在神经网络的前面几层中应对相同的图像区域有相似的反应。在后续的神经网络中再进行继承局部特征。

### 6.1.2. 限制多层感知机

![image-20211211160538975](http://cdn.nefu-yzk.top/img/image-20211211160538975.png)

#### 6.1.2.1. 平移不变性

![image-20211211160828943](http://cdn.nefu-yzk.top/img/image-20211211160828943.png)

#### 6.1.2.2. 局部性

![image-20211211161602713](http://cdn.nefu-yzk.top/img/image-20211211161602713.png)

对于❓那句话我的理解是：多层感知机每一层学习的内容都是全部的信息，而CNN每一次学习到的都是局部的信息，当卷积核越小的时候，学习到的信息越少，差异就越大。

### 6.1.4 通道

图像一般包含三个通道/三种原色（红色、绿色和蓝色）。 实际上，图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含1024×1024×3个像素。**前两个轴与像素的空间位置有关，而第三个轴可以看作是每个像素的多维表示。**   

![image-20211211161927471](http://cdn.nefu-yzk.top/img/image-20211211161927471.png)

![image-20211211162257764](http://cdn.nefu-yzk.top/img/image-20211211162257764.png)

c 表示的是啥啊？

### 6.1.5. 小结

- 图像的平移不变性使我们以相同的方式处理局部图像，而不在乎它的位置。
- 局部性意味着计算相应的隐藏表示只需一小部分局部图像像素。
- 在图像处理中，卷积层通常比全连接层需要更少的参数，但依旧获得高效用的模型。
- 卷积神经网络（CNN）是一类特殊的神经网络，它可以包含多个卷积层。
- 多个输入和输出通道使模型在每个空间位置可以获取图像的多方面特征。

## 6.2. 图像卷积

### 6.2.1. 互相关运算

![image-20211211162706907](http://cdn.nefu-yzk.top/img/image-20211211162706907.png)

在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。 当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。

![image-20211211162811704](http://cdn.nefu-yzk.top/img/image-20211211162811704.png)

```python
import torch
from torch import nn
from d2l import torch as d2l

# K表示的是卷积核
def corr2d(X, K):  #@save
    """计算二维互相关运算"""
    h, w = K.shape
    # 定义好输出Y的大小
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):   # 遍历行
        for j in range(Y.shape[1]):  # 遍历列
            # 其中i:i+h 其实就是h行   j:j+w其实就是w列
            # 其中X[i:i + h, j:j + w]就是在X中截取卷积核的大小
            # X[i:i + h, j:j + w] * K 即是点乘  对应位置上的元素相乘
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y

# 用于验证二维的互相关运算
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K)
```



### 6.2.2. 卷积层

卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。 所以，卷积层中的两个被训练的参数是**卷积核权重(w)和标量偏置(b)**。 就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也**随机初始化卷积核权重。**

> 注：其中偏置是进行权重计算之后对于矩阵中的每个数值都加上bias的值

基于上面定义的`corr2d`函数实现二维卷积层。在`__init__`构造函数中，将`weight`和`bias`声明为两个模型参数。前向传播函数调用`corr2d`函数并添加偏置。

```python
class Conv2D(nn.Module):
    # __init__表示实例化时需要指定卷积核的大小
    def __init__(self, kernel_size):
        super().__init__()
        # 通过nn.Parameter声明weight以及bias为模型的参数
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

我们通常将带有hxw卷积核的卷积层称为hxw卷积层，例如带有3x3卷积核的卷积层，我们称为3x3卷积层。

### 6.2.3. 图像中目标的边缘检测

![image-20211211164136433](http://cdn.nefu-yzk.top/img/image-20211211164136433.png)

```python
X = torch.ones((6, 8))
X[:, 2:6] = 0  # 将2-5列置为0
X

# 构造一个1x2的卷积核，并进行互相关运算
K = torch.tensor([[1.0, -1.0]])

# 对参数X（输入）和K（卷积核）执行互相关运算。
Y = corr2d(X, K)
Y
# 卷积核K只可以检测垂直边缘|，无法检测水平边缘——。
corr2d(X.t(), K)
```

### 6.2.4. 学习卷积核

通过仅查看“输入-输出”对来学习由`X`生成`Y`的卷积核。

在每次迭代中，我们比较`Y`与卷积层输出的平方误差，然后计算梯度来更新卷积核。

```python
# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)  # 使用内置的二维卷积层

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # 学习率

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()  # 表示每一次循环都将模型参数的梯度清0，避免进行累积运算
    l.sum().backward()  # 梯度只能为标量（即一个数）输出隐式地创建
    # 当输出不是标量时，调用.backward()就会出错
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')
```

### 6.2.5 特征映射和感受野

输出的卷积层有时被称为*特征映射*（feature map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。

在CNN中，对于某一层的任意元素x，其*感受野*（receptive field）是指在前向传播期间可能影响x计算的所有元素（来自所有先前层）。

![image-20211211170917778](http://cdn.nefu-yzk.top/img/image-20211211170917778.png)

### 6.2.6 小结

- 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。
- 我们可以设计一个卷积核来检测图像的边缘。
- 我们可以从数据中学习卷积核的参数。
- 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。
- 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。

## 6.3. 填充和步幅

卷积的输出形状取决于输入形状和卷积核的形状。填充和步幅也会影响到输出的大小。

> 填充可以减少原始图像边界丢失的有用的信息
>
> 步幅则可以大幅度的降低图像的宽度和高度



### 6.3.1. 填充

![image-20211211171440357](http://cdn.nefu-yzk.top/img/image-20211211171440357.png)

![image-20211211171805085](http://cdn.nefu-yzk.top/img/image-20211211171805085.png)

卷积核的大小选择奇数的原因是保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。

对于任何二维张量`X`，当满足： 1. 内核的大小是奇数； 2. 所有边的填充行数和列数相同； 3. 输出与输入具有相同高度和宽度 则可以得出：输出`Y[i, j]`是通过以输入`X[i, j]`为中心，与卷积核进行互相关计算得到的。

比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层(3x3的卷积层)，并在所有侧边填充1个像素。给定高度和宽度为8的输入(填充之后输入大小变为10x10)，则输出的高度和宽度也是8。

```python
import torch
from torch import nn

# 为了方便起见，我们定义了一个计算卷积层的函数。
# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数
def comp_conv2d(conv2d, X):
    # 这里的（1，1）表示批量大小和通道数都是1
    X = X.reshape((1, 1) + X.shape) # (1, 1) + X.shape将变为4维的
    Y = conv2d(X)
    # 省略前两个维度：批量大小和通道
    return Y.reshape(Y.shape[2:])

# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列
# padding为1即是将原来的输入上下左右都+1，即是最后的输入在宽高的基础上+2
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape

# 当卷积内核的高度和宽度不同时，我们可以填充不同的高度和宽度，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape # 即是宽高分别+4和+2   12x10  - 4x2 = 8x8
```



### 6.3.2. 步幅

![image-20211211172922152](http://cdn.nefu-yzk.top/img/image-20211211172922152.png)

![image-20211211173131717](http://cdn.nefu-yzk.top/img/image-20211211173131717.png)

```python
# 其实此时p=2 k=3即p=k-1，所以结果为X的高宽减半
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape

# X的输入为8x8  加上padding后为8x10
# 经过卷积为 8x10 - 2x4 = 6 x 6
# (6+3-1)/3 x (6+4-1)/4 = 2x2
# 3 4分别表示为垂直移动和水平移动
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))
comp_conv2d(conv2d, X).shape
```

![image-20211211174007901](http://cdn.nefu-yzk.top/img/image-20211211174007901.png)

## 6.3.3. 小结

- 填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。
- 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的1/n（n是一个大于11的整数）。
- 填充和步幅可用于有效地调整数据的维度。



## 6.4. 多输入多输出通道

![image-20211211174254960](http://cdn.nefu-yzk.top/img/image-20211211174254960.png)

### 6.4.1. 多输入通道

![image-20211211175501122](http://cdn.nefu-yzk.top/img/image-20211211175501122.png)

为了加深理解，我们实现一下多输入通道互相关运算。 简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加。

```python
import torch
from d2l import torch as d2l

def corr2d_multi_in(X, K):
    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起
    # zip将对应的x，k打包成一个个tuple进行返回
    # X,K中的第一个维度即是通道维
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K)) 

X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])
X.shape  # (2, 3, 3)  即是X含有2个二维数组
corr2d_multi_in(X, K)
```



### 6.4.2. 多输出通道

在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过**减少空间分辨率**以获得更大的通道深度。直观地说，我们可以**将每个通道看作是对不同特征的响应。**而现实可能更为复杂一些，**因为每个通道不是独立学习的，而是为了共同使用而优化的**。因此，多输出通道并不仅是学习多个单通道的检测器。

> 空间分辨率可以抽象的理解为图像中楼层的高度

```python
def corr2d_multi_in_out(X, K):
    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。
    # 最后将所有结果都叠加在一起
    # corr2d_multi_in(X, k) for k in K：取出K的第一维进行循环，即对于(3,2,2,2)而言，取出的是3
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0) # 0表示垂直方向上进行叠加

K = torch.stack((K, K + 1, K + 2), 0) # 一开始K的大小为(2,2,2)  stack之后为(3,2,2,2)
# 其中(3,2,2,2)的第一维为通道维

# 理解stack函数
# 假设是时间步T1的输出 3x3  二维数据  stack之后变为3维的
T1 = torch.tensor([[1, 2, 3],
        		[4, 5, 6],
        		[7, 8, 9]])
# 假设是时间步T2的输出
T2 = torch.tensor([[10, 20, 30],
        		[40, 50, 60],
        		[70, 80, 90]])

print(torch.stack((T1,T2),dim=0).shape)  # torch.Size([2, 3, 3]) 第一个参数变化
print(torch.stack((T1,T2),dim=1).shape)  # torch.Size([3, 2, 3]) 第二个参数变化
print(torch.stack((T1,T2),dim=2).shape)  # torch.Size([3, 3, 2]) 第三个参数变化
print(torch.stack((T1,T2),dim=3).shape) # # 选择的dim>len(outputs)，所以报错

# 对输入张量X与卷积核张量K执行互相关运算。现在的输出包含 3 个通道，第一个通道的结果与先前输入张量X和多输入单输出通道的结果一致。
corr2d_multi_in_out(X, K)
```

### 6.4.3. 1×1 卷积层

卷积的本质是有效提取相邻像素间的相关特征。

因为使用了最小窗口，1×1卷积失去了卷积层的特有能力——**在高度和宽度维度上，识别相邻元素间相互作用的能力。** 其实1×1卷积的唯一计算发生在通道上。

![image-20211211191600709](http://cdn.nefu-yzk.top/img/image-20211211191600709.png)

全连接层实现1×11×1卷积。 请注意，我们需要对输入和输出的数据形状进行微调。

```python
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    # 全连接层中的矩阵乘法
    Y = torch.matmul(K, X)
    return Y.reshape((c_o, h, w))

# 当执行 1×1 卷积运算时，上述函数相当于先前实现的互相关函数corr2d_multi_in_out。让我们用一些样本数据来验证这一点。
X = torch.normal(0, 1, (3, 3, 3))
K = torch.normal(0, 1, (2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)
Y2 = corr2d_multi_in_out(X, K)
assert float(torch.abs(Y1 - Y2).sum()) < 1e-6
```

### 6.4.4. 小结

- 多输入多输出通道可以用来扩展卷积层的模型。
- 当以每像素为基础应用时，$1×1$卷积层相当于全连接层。
- $1×1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。

## 6.5. 汇聚层

在现实中，随着拍摄角度的移动，任何物体几乎不可能发生在同一像素上。即使用三脚架拍摄一个静止的物体，由于快门的移动而引起的相机振动，可能会使所有物体左右移动一个像素（除了高端相机配备了特殊功能来解决这个问题）。

*汇聚*（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。

### 6.5.1. 最大汇聚层和平均汇聚层

![image-20211211202153753](http://cdn.nefu-yzk.top/img/image-20211211202153753.png)

池化层可以很好的降低对于位置的敏感程度

在下面的代码中的`pool2d`函数，我们实现汇聚层的前向传播。 此功能类似于 [6.2节](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/conv-layer.html#sec-conv-layer)中的`corr2d`函数。 然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。

```python
pythonimport torch
from torch import nn
from d2l import torch as d2l

def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size
    # 首先定义出输出大小
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
    return Y
```

我们可以构建 [图6.5.1](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/pooling.html#fig-pooling)中的输入张量`X`，验证二维最大汇聚层的输出。

```python
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
pool2d(X, (2, 2))
pool2d(X, (2, 2), 'avg')
```

### 6.5.2. 填充和步幅

与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。 下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。 我们首先构造了一个输入张量`X`，它有四个维度，其中样本数和通道数都是1。

> 默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同。

```python
X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))
# 第一个为通道维 ，第二个为样本数的维度
X

# 默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同。 因此，如果我们使用形状为(3, 3)的汇聚窗口，那么默认情况下，我们得到的步幅形状为(3, 3)。
pool2d = nn.MaxPool2d(3)  # 内置的函数 步幅为(3, 3)
pool2d(X)  # (未指定padding) 即是对于4x4的而言，对于输入只能框住第一个3x3的 所以输出为1

# 填充和步幅可以手动设定。
pool2d = nn.MaxPool2d(3, padding=1, stride=2)  # 填充padding和stride
pool2d(X)   # 经过填充之后 4x4->6x6

# 当然，我们可以设定一个任意大小的矩形汇聚窗口，并分别设定填充和步幅的高度和宽度。
pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))
pool2d(X)
```

### 6.5.3. 多个通道

在处理多通道输入数据时，**汇聚层在每个输入通道上单独运算**，而不是像卷积层一样在通道上对输入进行**汇总**。 这意味着**汇聚层的输出通道数与输入通道数相同**。 下面，我们将在通道维度上连结张量`X`和`X + 1`，以构建具有2个通道的输入。

```python
X = torch.cat((X, X + 1), 1)  # 区分cat与stack的区别 cat维度不变 stack增加了维度
X  # (1,2,4,4)  
# 汇聚后输出通道的数量仍然是2
pool2d = nn.MaxPool2d(3, padding=1, stride=2)
pool2d(X)


X = torch.stack((X, X + 1), 1) 
X # (1,2,1,4,4)  stack增加了维度

# 池化层单独的在每个通道出进行计算
```

### 6.5.4. 小结

- 对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值。
- 汇聚层的主要优点之一是减轻卷积层对位置的过度敏感。
- 我们可以指定汇聚层的填充和步幅。
- 使用最大汇聚层以及大于1的步幅，**可减少空间维度**（如高度和宽度）。
- 汇聚层的输出通道数与输入通道数相同。

## 6.6. 卷积神经网络（LeNet）

### 6.6.1. LeNet

体来看，LeNet（LeNet-5）由两个部分组成：

- 卷积编码器：由两个卷积层组成;
- 全连接层密集块：由三个全连接层组成。

该架构如 [图6.6.1](https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/lenet.html#img-lenet)所示。

![image-20211211214621383](http://cdn.nefu-yzk.top/img/image-20211211214621383.png)

每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层。

一个卷积块中包含了不同的层

卷积的输出形状由批量大小、通道数、高度、宽度决定。

![image-20211211215805478](http://cdn.nefu-yzk.top/img/image-20211211215805478.png)

通过下面的LeNet代码，你会相信用深度学习框架实现此类模型非常简单。我们只需要实例化一个`Sequential`块并将需要的层连接在一起。

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    # 输入通道数，输出通道数
    # nn.Conv2d(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True))
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Flatten(), #通过Flatten将维度拉成二维，(样本数, 样本的平面向量表示)
    # 其中16*5*5是上一次的输出算出来的
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),
    nn.Linear(84, 10))

# (1,1,28,28) 表示样本数、通道数
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
for layer in net:
    X = layer(X)
    # __class__.__name__打印出每一层的名字
    print(layer.__class__.__name__,'output shape: \t',X.shape)
```

### 6.6.2. 模型训练

现在我们已经实现了LeNet，让我们看看LeNet在Fashion-MNIST数据集上的表现。

```python
batch_size = 256
# batch_size表示每次读取样本数为设定大小的数量
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)
```

虽然卷积神经网络的参数较少，但与深度的多层感知机相比，它们的计算成本仍然很高，因为每个参数都参与更多的乘法。 如果你有机会使用GPU，可以用它加快训练。

```python
def evaluate_accuracy_gpu(net, data_iter, device=None): #@save
    """使用GPU计算模型在数据集上的精度"""
    if isinstance(net, nn.Module):
        net.eval()  # 设置为评估模式，不调用dropout
        if not device: # 如果没有指定device，则调用默认模型参数所处的device
            device = next(iter(net.parameters())).device
    # 正确预测的数量，总预测的数量
    metric = d2l.Accumulator(2)  # 指定存储了两个可以进行累加的变量
    with torch.no_grad():  # 下面的计算中不进行grad 梯度的计算
        for X, y in data_iter:
            if isinstance(X, list):  # 判断X是否是list的实例
                # BERT微调所需的（之后将介绍）
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)  # 将数据移到指定的设备中
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]
```

为了使用GPU，我们还需要一点小改动。 与 [3.6节](https://zh-v2.d2l.ai/chapter_linear-networks/softmax-regression-scratch.html#sec-softmax-scratch)中定义的`train_epoch_ch3`不同，在进行正向和反向传播之前，我们需要将每一小批量数据移动到我们指定的设备（例如GPU）上。

```python
#@save
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    """用GPU训练模型(在第六章定义)"""
    def init_weights(m):
        # 对属于nn.Linear以及nn.Conv2d的模型进行参数初始化
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight) 
    net.apply(init_weights)  # 应用到net网络中的指定层
    print('training on', device)
    net.to(device) # 将网络移到指定的设备上
    # 构造一个optimizer对象，该对象能保存当前的参数状态并且基于计算梯度更新参数
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = nn.CrossEntropyLoss()  # 使用模型的交叉熵损失函数
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        # 训练损失之和，训练准确率之和，范例数
        metric = d2l.Accumulator(3)
        net.train() # 进行训练模式
        for i, (X, y) in enumerate(train_iter):  # enumerate返回index和tuple
            timer.start()
            optimizer.zero_grad()  # 计算前先将原先的梯度进行清0，避免累加运算
            X, y = X.to(device), y.to(device)  # 将数据进行移动
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()  # 进行反向传播，更新参数
            optimizer.step()  # 更新所有的参数
            # 可以使用 with torch.no_grad():，强制之后的内容不进行计算图构建。
            with torch.no_grad(): 
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')
    

# 现在，我们训练和评估LeNet-5模型。
lr, num_epochs = 0.9, 10  # 指定学习率和训练批次
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

![image-20211211222916385](http://cdn.nefu-yzk.top/img/image-20211211222916385.png)

### 6.6.3. 小结

- 卷积神经网络（CNN）是一类使用卷积层的网络。
- 在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。
- 为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，**逐渐降低其表示的空间分辨率，同时增加通道数。**
- 在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。
  - **注：在全连接层之前，需要将卷积层得出的结果进行拉平处理，保留成二维形式**
- LeNet是最早发布的卷积神经网络之一。

