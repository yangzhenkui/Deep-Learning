

```python
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
import matplotlib.pyplot as plt
import torchvision.models as models
# 打印进度条使用的
from tqdm import tqdm
import seaborn as sns

# 看看读取的label数据的样子
label_dataframe = pd.read_csv('../input/classify-leaves/train.csv')
label_dataframe.head(5)  # 查看前5条数据

# 查看数据集的描述
label_dataframe.describe()

# 画出每一种叶子的数量以及分布情况
def barw(ax):
    for p in ax.patches:
        val = p.get_width()
        x = p.get_x() + val
        y = p.get_y() + p.get_height() / 2
        ax.annotate(round(val, 2), (x, y))
        
plt.figure(figsize = (15, 30))
ax0 = sns.countplot(y=label_dataframe['label'], order=label_dataframe['label'].value_counts().index)
barw(ax0)
plt.show()

# 将文件进行排序，将同一种类型的叶子排在一起
leaves_labels = sorted(list(set(label_dataframe['label']))) # 先进行去重，然后转为列表，对列表进行排序
n_classes = len(leaves_labels)
print(n_classes)
leaves_labels[0:10]

# 将label转为对应的数值，方便后面进行分类
class_to_num = dict(zip(leaves_labels, range(n_classes)))
class_to_num

# 再转换回来，方便最后预测的时候进行使用
num_to_class = {v : k for k,v in class_to_num.items()}
num_to_class

# 定义一个数据加载
class LeavesData(Dataset):
    def __init__(self, csv_path, file_path, mode='train', valid_ratio=0.2, resize_height = 256, resize_width = 256):
        """
            csv_path: csv文件路径
            file_path: 图像文件路径
            vaild_ratio: 验证集的比例
            mode: 指明是训练模式还是验证模式
        """
        self.resize_height = resize_height
        self.resize_width = resize_width
        self.file_path = file_path
        self.mode = mode
        
        # header=None表示去掉表头部分
        self.data_info = pd.read_csv(csv_path, header=None)
        
        self.data_len = len(self.data_info.index) - 1
        self.train_len = int(self.data_len*(1-valid_ratio))
        
        if mode == 'train':
            # 从第二行开始到train_len的长度， 0表示只要第一列的数据
            self.train_image = np.asarray(self.data_info.iloc[1:self.train_len, 0])  # 对应的数据是 images/0.jpg
            self.train_label = np.asarray(self.data_info.iloc[1:self.train_len, 1])
            
            self.image_arr = self.train_image
            self.label_arr = self.train_label
            
        elif mode == 'valid':
            self.valid_image = np.asarray(self.data_info.iloc[self.train_len:, 0])
            self.valid_label = np.asarray(self.data_info.iloc[self.train_len:, 1])
            
            self.image_arr = self.valid_image
            self.label_arr = self.valid_label
            
        elif mode == 'test':
            self.test_image = np.asarray(self.data_info.iloc[1:, 0])
            self.image_arr = self.test_image
        
        self.real_len = len(self.image_arr)
        print(f'Finished reading the {mode} set of leaves Dataset ({self.real_len} samples found)')
        
    def __getitem__(self, index):
        single_image_name = self.image_arr[index]
        img_as_img = Image.open(self.file_path + single_image_name)  # 得到每张图片的完整路径
        
        if self.mode == 'train':
            # 进行数据增强
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.RandomHorizontalFlip(p=0.5),    # 以一定的概率进行水平翻转
                transforms.ToTensor()
            ])
        else:
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                # transforms.RandomHorizontalFlip(p=0.5), # 以一定的概率进行水平翻转
                transforms.ToTensor()  # 将结果作为一个4D的矩阵
            ])
            
        img_as_img = transform(img_as_img)
        
            
        if self.mode == 'test':
            return img_as_img
        else:
            label = self.label_arr[index]  # 得到label的string类型
            number_label = class_to_num[label]  # 找到label的对应的数字
            return img_as_img, number_label  # 返回图像数据以及对应的标签
        
    def __len__(self):
        return self.real_len
    
 
train_path = '../input/classify-leaves/train.csv'
test_path = '../input/classify-leaves/test.csv'
img_path = '../input/classify-leaves/'

train_dataset = LeavesData(train_path, img_path, mode='train')
val_dataset = LeavesData(train_path, img_path, mode='valid')
test_dataset = LeavesData(test_path, img_path, mode='test')

print(train_dataset)
print(val_dataset)
print(test_dataset)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                          batch_size = 8,
                                          shuffle=False,
                                          num_workers=5  # 表示工作线程的数量
                                          )

val_loader = torch.utils.data.DataLoader(dataset=val_dataset,
                                        batch_size=8,
                                        shuffle=False,
                                        num_workers=5
                                        )

test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                        batch_size=8,
                                        shuffle=False,
                                        num_workers=5
                                        )

# 展示一下数据
def im_convert(tensor):
    
    image = tensor.to('cpu').clone().detach()
    image = image.numpy().squeeze()
    image = image.transpose(1, 2, 0)
    image = image.clip(0, 1)
    
    return image

fig = plt.figure(figsize=(20,12))
columns = 4
rows = 2

dataiter = iter(val_loader)
inputs, classes = dataiter.next()

for idx in range(columns*rows):
    ax = fig.add_subplot(rows, columns, idx+1, xticks=[], yticks=[])
    ax.set_title(num_to_class[int(classes[idx])])
    plt.imshow(im_convert(inputs[idx]))

plt.show()

def get_device():
    return 'cuda' if torch.cuda.is_available() else 'cpu'

device = get_device()

print(device)

def set_parameter_requires_grad(model, feature_extracting):
    if feature_extracting:
        model = model
        for param in model.parameters():
            param.requires_grad = False
            
def res_model(num_classes, feature_extract = False, use_pretrained = True):
    
    model_ft = models.resnet34(pretrained=use_pretrained)
    set_parameter_requires_grad(model_ft, feature_extract)
    num_ftrs =  model_ft.fc.in_features  # 求出全连接层的特征数
    model_ft.fc = nn.Sequential(nn.Linear(num_ftrs, num_classes))
    
    return model_ft

learning_rate = 3e-4
weight_decay = 1e-3
num_epoch = 50
model_path = './pre_res_model.ckpt'

model = res_model(176)
model = model.to(device)
model.device = device

criterion = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)  # 定义优化器

n_epochs = num_epoch
best_acc = 0.0

for epoch in range(n_epochs):
    model.train()
    train_loss = []
    train_accs = []
    for batch in tqdm(train_loader): # 因为加了tqdm，所以下面的打印语句都会伴随着进度条
        imgs, labels = batch
        imgs = imgs.to(device)
        labels = labels.to(device)
        
        logits = model(imgs)  # 得到一个softmax分类后的结果
        loss = criterion(logits, labels)  # 通过预测出的结果与正确的labels进行损失函数的计算
        optimizer.zero_grad()
        loss.backward()  # 默认调用了loss.sum().backward()
        optimizer.step()  # 反向传播后进行参数的更新
        
        acc = (logits.argmax(dim=-1) == labels).float().mean() # 统计预测正确的个数/总个数的结果
        
        train_loss.append(loss.item())
        train_accs.append(acc)
    train_loss = sum(train_loss) / len(train_loss)
    train_acc = sum(train_accs) / len(train_accs)
    
    print(f'[Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}')
    
    
    model.eval()  # 调成验证模式，该模式下不进行参数的更新
    
    valid_loss = []
    valid_accs = []
    
    for batch in tqdm(val_loader):
        imgs, labels = batch
        labels = labels.to(device)
        with torch.no_grad():
            logits = model(imgs.to(device))  # 得到一个softmax分类后的结果
            
        loss = criterion(logits, labels)  # 通过预测出的结果与正确的labels进行损失函数的计算
        
        
        acc = (logits.argmax(dim=-1) == labels).float().mean() # 统计预测正确的个数/总个数的结果
        
        valid_loss.append(loss.item())
        valid_accs.append(acc)
    valid_loss = sum(valid_loss) / len(valid_loss)
    valid_acc = sum(valid_accs) / len(valid_accs)
    
    print(f'[Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}')
    
    if valid_acc > best_acc:
        best_acc = valid_acc
        torch.save(model.state_dict(), model_path)
        print(f'saving model with acc {best_acc:.3f}')
```

